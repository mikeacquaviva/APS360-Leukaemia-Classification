{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikeacquaviva/APS360-Leukaemia-Classification/blob/main/svm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "References: 1. https://www.youtube.com/watch?v=7sz4WpkUIIs"
      ],
      "metadata": {
        "id": "ng3FCJ9jmrpG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports**"
      ],
      "metadata": {
        "id": "wEYnHG-OhSTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import dataset from: https://www.kaggle.com/datasets/mehradaria/leukemia"
      ],
      "metadata": {
        "id": "2VfSp16IiVwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm, datasets\n",
        "import sklearn.model_selection as model_selection\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "H0bLarW9QxmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import random_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "SPw6O3B9UvxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "a8lSATN4Sf5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = (\"/content/gdrive/MyDrive/APS360/baseline/svm_images\")\n",
        "\n",
        "benign_dir = (\"/content/gdrive/MyDrive/APS360/baseline/svm_images/benign\")\n",
        "early_dir = (\"/content/gdrive/MyDrive/APS360/baseline/svm_images/early\")\n",
        "pre_dir = (\"/content/gdrive/MyDrive/APS360/baseline/svm_images/pre\")\n",
        "pro_dir = (\"/content/gdrive/MyDrive/APS360/baseline/svm_images/pro\")"
      ],
      "metadata": {
        "id": "dGSFERD4SZop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform = transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                      transforms.ToTensor()])\n",
        "classes = ['benign', 'early', 'pre', 'pro']\n",
        "data = datasets.ImageFolder(data_dir, transform = data_transform)\n",
        "#data = datasets.ImageFolder(benign_dir, transform = data_transform)\n",
        "#pre_data = datasets.ImageFolder(pre_dir, transform = data_transform)\n",
        "#pro_data = datasets.ImageFolder(pro_dir, transform = data_transform)"
      ],
      "metadata": {
        "id": "PgSoBTD7ULHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y_labels = ['benign', 'early', 'pre', 'pro']\n",
        "#y_train = ['benign', 'early', 'pre', 'pro']"
      ],
      "metadata": {
        "id": "p37Pg35If2M0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = random_split(data, [0.8, 0.2], generator=torch.Generator().manual_seed(0)) \n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(X_train, batch_size=27, shuffle=True)\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "img_train, y_train = next(dataiter)\n",
        "images_train = img_train.numpy()\n",
        "\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, int(20/2), idx+1, xticks=[], yticks=[])\n",
        "    plt.imshow(np.transpose(images_train[idx], (1, 2, 0)))\n",
        "    ax.set_title(classes[y_train[idx]])\n",
        "#X_train, X_test, y_train, y_test = model_selection.train_test_split(data, y_labels, train_size=0.80, test_size=0.20, random_state=101)"
      ],
      "metadata": {
        "id": "hc9QClL9PozC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train, X_test = random_split(data, [0.8, 0.2], generator=torch.Generator().manual_seed(0)) \n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(X_test, batch_size=27, shuffle=True)\n",
        "\n",
        "dataiter = iter(test_loader)\n",
        "images, y_test = next(dataiter)\n",
        "img_test, y_test = next(dataiter)\n",
        "images_test = img_train.numpy()"
      ],
      "metadata": {
        "id": "t3YhjQ8IkQbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.SVC(gamma=0.001)"
      ],
      "metadata": {
        "id": "v6Acxut_mAtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#clf.fit(X_train, y_train.ravel())"
      ],
      "metadata": {
        "id": "q1YM7z6Yl7Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(images_train[0].shape)"
      ],
      "metadata": {
        "id": "NGSBkG1v2flo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1).fit(images_train, y_train)\n",
        "#poly = svm.SVC(kernel='poly', degree=3, C=1).fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Ysy5Iul2PTv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly_pred = poly.predict(A_test)\n",
        "rbf_pred = rbf.predict(A_test)"
      ],
      "metadata": {
        "id": "jUTEdTwsQcuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly_accuracy = accuracy_score(B_test, poly_pred)\n",
        "poly_f1 = f1_score(B_test , poly_pred, average='weighted')\n",
        "print('Accuracy (Polynomial Kernel): ', \"%.2f\" % (poly_accuracy*100))\n",
        "print('F1 (Polynomial Kernel): ', \"%.2f\" % (poly_f1*100))"
      ],
      "metadata": {
        "id": "jfXJ9GaRQhtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P295SSZMg7qP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "#train_subdir_path \n",
        "#test_subdir_path\n",
        "#val_subdir_path\n",
        "\n",
        "#def dataloader(batch_size, test_dir, train_dir, val_dir):\n",
        "  trainset = torchvision.datasets(train_dir)\n",
        "  train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, \n",
        "                                             shuffle=True, num_workers=1)\n",
        "  testset = torchvision.datasets(test_dir)\n",
        "  test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                             shuffle=True, num_workers=1)\n",
        "  valset = torchvision.datasets(val_dir)\n",
        "  val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
        "                                           shuffle = True, num_workers=1)\n",
        "  return test_loader, train_loader, val_loader\n",
        "  "
      ],
      "metadata": {
        "id": "M8AJAf60iPpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cell_df = pd.read_csv('') #assume that we have created a "
      ],
      "metadata": {
        "id": "FRZFSZq2hcUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_df = cell_df()\n",
        "x = np.asarray(features_df)"
      ],
      "metadata": {
        "id": "2oYPHndikkgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM "
      ],
      "metadata": {
        "id": "IEX99F-MlB9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "import sklearn.model_selection as model_selection\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "classifier = svm.SVC(kernel = 'linear', gamma = 'auto', C=2) #support vector classifiers, rpf is default kernel\n",
        "classifier.fit()"
      ],
      "metadata": {
        "id": "dm7BPlGFk-e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ],
      "metadata": {
        "id": "oYLIddKQmGG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test)) \n",
        "#this prints out the confusion matrix where the recall is an  \n",
        "#important metric for medical diagnosis"
      ],
      "metadata": {
        "id": "kTtvX2chmHiC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}